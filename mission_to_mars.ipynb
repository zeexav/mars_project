{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the news titles and paragraph data\n",
    "\n",
    "space_data = soup.find_all('div', class_ = \"list_text\")\n",
    "\n",
    "news_titles = []\n",
    "news_p = []\n",
    "for slide in space_data:\n",
    "    headline_tile = slide.find('a').text\n",
    "    news_tease = slide.find('div', class_ = 'article_teaser_body').text\n",
    "    news_titles.append(headline_tile)\n",
    "    news_p.append(news_tease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(news_titles))\n",
    "print(len(news_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(img_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = browser.html\n",
    "soup = BeautifulSoup(site, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/mediumsize/PIA18886_ip.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA18886_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "#get Mars featured image\n",
    "\n",
    "root_url = 'https://www.jpl.nasa.gov'\n",
    "\n",
    "pg_header = soup.find_all('div', class_ = 'carousel_items')\n",
    "\n",
    "\n",
    "for item in pg_header:\n",
    "    articles = item.find('article')\n",
    "    footer = articles.find('footer')\n",
    "    link = footer.find('a')\n",
    "    img_path = link['data-fancybox-href']\n",
    "    print(img_path)\n",
    "\n",
    "featured_image_url = root_url + img_path\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all mars images\n",
    "root_url = 'https://www.jpl.nasa.gov'\n",
    "all_images = soup.find_all('li', class_ = \"slide\")\n",
    "\n",
    "img_paths = []\n",
    "for image in all_images:\n",
    "    link = image.find('a')\n",
    "    \n",
    "    try:\n",
    "        img_link = link['data-fancybox-href']\n",
    "        img_path = root_url + img_link\n",
    "        img_paths.append(img_path)\n",
    "    except:\n",
    "        pass\n",
    "    #print(img_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Weather. scrape the latest Mars weather tweet from the page\n",
    "\n",
    "tweet_site = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(tweet_site)\n",
    "\n",
    "tweet_site = browser.html\n",
    "soup = BeautifulSoup(tweet_site, 'lxml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InSight sol 135 (2019-04-13) low -96.5ºC (-141.8ºF) high -16.6ºC (2.2ºF)\\nwinds from the SW at 4.2 m/s (9.4 mph) gusting to 11.3 m/s (25.3 mph)\\npressure at 7.30 hPapic.twitter.com/bRsLlzn4M0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = soup.find_all('ol', class_ = \"stream-items js-navigable-stream\")\n",
    "\n",
    "for tweet in tweets:\n",
    "    section = tweet.find('div', class_ = \"content\")\n",
    "    sect_loc = section.find('div', class_=\"js-tweet-text-container\")\n",
    "    p_text = sect_loc.find('p').text\n",
    "    \n",
    "p_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Facts. use Pandas to scrape the table containing facts about the planet\n",
    "\n",
    "facts_site = 'https://space-facts.com/mars/'\n",
    "browser.visit(facts_site)\n",
    "\n",
    "facts_site = browser.html\n",
    "soup = BeautifulSoup(facts_site, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 'Equatorial Diameter:', 1: '6,792 km'},\n",
       " {0: 'Polar Diameter:', 1: '6,752 km'},\n",
       " {0: 'Mass:', 1: '6.42 x 10^23 kg (10.7% Earth)'},\n",
       " {0: 'Moons:', 1: '2 (Phobos & Deimos)'},\n",
       " {0: 'Orbit Distance:', 1: '227,943,824 km (1.52 AU)'},\n",
       " {0: 'Orbit Period:', 1: '687 days (1.9 years)'},\n",
       " {0: 'Surface Temperature:', 1: '-153 to 20 °C'},\n",
       " {0: 'First Record:', 1: '2nd millennium BC'},\n",
       " {0: 'Recorded By:', 1: 'Egyptian astronomers'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# facts_table = soup.find_all('table')\n",
    "\n",
    "# mars_facts = pd.read_html(str(facts_table))\n",
    "\n",
    "# for row in mars[0]:\n",
    "#     row.split('0:')\n",
    "# mars_table = mars_facts[0].\n",
    "# mars_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Equatorial Diameter:': '6,792 km', 'Polar Diameter:': '6,752 km', 'Mass:': '6.42 x 10^23 kg (10.7% Earth)', 'Moons:': '2 (Phobos & Deimos)', 'Orbit Distance:': '227,943,824 km (1.52 AU)', 'Orbit Period:': '687 days (1.9 years)', 'Surface Temperature:': '-153 to 20 °C', 'First Record:': '2nd millennium BC', 'Recorded By:': 'Egyptian astronomers'}\n"
     ]
    }
   ],
   "source": [
    "facts_table = soup.find_all('table')\n",
    "\n",
    "mars_facts = pd.read_html(str(facts_table))\n",
    "\n",
    "#convert to dataframe and drop index\n",
    "mars_facts_df = mars_facts[0]\n",
    "mars_facts_df.columns = ['Fact', 'Values']\n",
    "\n",
    "mars_facts_df.set_index('Fact', drop = True, inplace = True)\n",
    "\n",
    "#convert new dataframe to dictionary\n",
    "\n",
    "mars_table = mars_facts_df.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "for row, vals in mars_table.items():\n",
    "    m_data = vals;\n",
    "    print(m_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "hemis_site = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemis_site)\n",
    "\n",
    "hemis_site = browser.html\n",
    "soup = BeautifulSoup(hemis_site, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cerberus Hemisphere Enhanced', 'Schiaparelli Hemisphere Enhanced', 'Syrtis Major Hemisphere Enhanced', 'Valles Marineris Hemisphere Enhanced']\n",
      "------\n",
      "['https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced', 'https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced', 'https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced', 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced']\n"
     ]
    }
   ],
   "source": [
    "#get the urls and image names for each hemisphere.\n",
    "# Step 1 get the hemisphere names and the link to each hemisphere page\n",
    "results = soup.find_all('div', class_ = \"item\")\n",
    "base_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "hemi_nm  = []\n",
    "hemi_url = []\n",
    "for result in results:\n",
    "    desc = result.find('div', class_ = \"description\")\n",
    "    links_all = desc.find('a', class_ = \"itemLink product-item\")\n",
    "    link = links_all['href']\n",
    "    title  = links_all.find('h3').text\n",
    "    full_link = base_url + link\n",
    "    hemi_url.append(full_link)\n",
    "    hemi_nm.append(title)\n",
    "\n",
    "print(hemi_nm)\n",
    "print(\"------\")\n",
    "print(hemi_url)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg\n",
      "https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg\n",
      "https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg\n",
      "https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg\n"
     ]
    }
   ],
   "source": [
    "# step 2: get the url for the full image by looping through hemi_url and using splinter to navigate to each page\n",
    "#then scraping the page\n",
    "\n",
    "img_base_url = 'https://astrogeology.usgs.gov'\n",
    "large_img_url = []\n",
    "\n",
    "for link in hemi_url:\n",
    "    link_text = link\n",
    "    img_site = f\"{link_text}\"\n",
    "    browser.visit(img_site)\n",
    "    img_site = browser.html\n",
    "    soup = BeautifulSoup(img_site, 'lxml')\n",
    "    hemi_info = soup.find_all('div', class_ = \"wide-image-wrapper \")\n",
    "    for item in hemi_info:\n",
    "        image = item.find('img', class_ = \"wide-image\")['src']\n",
    "        full_img_url = img_base_url + image\n",
    "        large_img_url.append(full_img_url)\n",
    "        print(full_img_url)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cerberus Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg',\n",
       " 'Schiaparelli Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg',\n",
       " 'Syrtis Major Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg',\n",
       " 'Valles Marineris Hemisphere Enhanced': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine hemisphere name and image url into a dictionary\n",
    "\n",
    "hemisphere_img_urls = dict(zip(hemi_nm,large_img_url ))\n",
    "\n",
    "hemisphere_img_urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
